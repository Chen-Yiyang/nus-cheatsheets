%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Original Source: Dave Richeson (divisbyzero.com), Dickinson College
% Modified By: Chen Yiyang
% 
% A one-size-fits-all LaTeX cheat sheet. Kept to two pages, so it 
% can be printed (double-sided) on one piece of paper
% 
% Feel free to distribute this example, but please keep the referral
% to divisbyzero.com
% 
% Guidance on the use of the Overleaf logos can be found here:
% https://www.overleaf.com/for/partners/logos 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[10pt,landscape,letterpaper]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{physics}  % for vectors
\usepackage{bbm}  % for mathbb-ed digits
%\usepackage{fonts}
\usepackage{multicol,multirow}
\usepackage{spverbatim}
\usepackage{graphicx}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
\usepackage[colorlinks=true,urlcolor=olgreen]{hyperref}
\usepackage{booktabs}
\usepackage{fontspec}
\setmainfont[Ligatures=TeX]{TeX Gyre Pagella}
\setsansfont{Fira Sans}
\setmonofont{Inconsolata}
\usepackage{unicode-math}
\setmathfont{TeX Gyre Pagella Math}
\usepackage{microtype}

\usepackage{empheq}

% new:
\def\MT@is@uni@comp#1\iffontchar#2\else#3\fi\relax{%
  \ifx\\#2\\\else\edef\MT@char{\iffontchar#2\fi}\fi
}
\makeatother

\ifthenelse{\lengthtest { \paperwidth = 11in}}
    { \geometry{margin=0.4in} }
	{\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
	}
\pagestyle{empty}
\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%x
                                {\sffamily\large}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                {-1explus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%
                                {\sffamily\normalsize\itshape}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {1ex plus .2ex}%
                                {\normalfont\small\itshape}}
\makeatother
\setcounter{secnumdepth}{0}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}
% -----------------------------------------------------------------------

\usepackage{academicons}

\begin{document}

\definecolor{mathBlue}{cmyk}{1,.72,0,.38}
\definecolor{defOrange}{cmyk}{0, 0.5, 1, 0.3}
\definecolor{codeInlineRed}{cmyk}{0, 0.9, 0.9, 0.45}

\everymath{\color{mathBlue}}
\everydisplay{\color{mathBlue}}

% for vector notation in this module
\newcommand{\vect}[1]{\pmb{#1}}
\newcommand{\deff}[1]{\textcolor{defOrange}{\textbf{#1}}}
\newcommand{\codein}[1]{\textcolor{codeInlineRed}{\texttt{#1}}}
\newcommand{\citeqn}[1]{\underline{\textit{#1}}}

\footnotesize
%\raggedright

\begin{center}
  {\huge\sffamily\bfseries CS4247 Cheatsheet} \huge\bfseries\\
  by Yiyang, AY22/23
\end{center}
\setlength{\premulticols}{0pt}
\setlength{\postmulticols}{0pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{1.8em}
\begin{multicols}{3}


% -----------------------------------------------------------------------
%\section{1. Modern OpenGL}
%\section{2. Geometric Transformation}
%\section{3. GLSL}

\section{Introduction}
\subsection{OpenGL Shaders}
\subsubsection{Vertex Shader}

\subsubsection{Fragment Shader}


\section{4. Texture Mapping}
\subsection{OpenGL Cube Map}





\section{5. Shaders}
\subsection{Cartoon Style Shading}
%TODO: very view-dependent

\subsection{Procedural Bump \& Normal Mapping}
Procedures for Procedural Bump Mapping:
\begin{enumerate}
	\item At each vertex, transform normal  \& tangent to eye space
	\item Interpolate eye-space normal \& tangent to fragments
	\item At each fragment, compute \deff{Binormal vector} \& compute tangent-space \deff{Perturbantion Vector} based on texture coordinates
	\item Transofmration perturbantion from tangent space to eye space and use it for lighting computation
\end{enumerate}
\deff{Binormal Vector} - unit vector perpendicular to both normal \& tangent vectors.

\smallskip

In \deff{Normal Mapping}, use a normal map where each texel contains 3 perturbation vector components in  RGB channels.
\\
\underline{Note}: Need to encode from $[–1,1]$ to $[0,1]$ for each value read.


\subsection{Refraction \& Reflection Mapping}
Procedures:
\begin{enumerate}
	\item Set up an \deff{Environment Map} (e.g. cubemap)
	\item Compute the refracted ray of the view ray
	\item Use (interpolated) refraction ray direction to access env.map at fragment shader
\end{enumerate}

\underline{Note}: [1] We only compute refraction at the first surface (entering the object) and ignore when the ray exits the object since it is too complicated. [2] Refraction mapping is similar to reflection mapping, but need to account for Fresnel Effects and Chromatic Aberration.

\subsubsection{Fresnel Effects}
\deff{Fresnel Effects} - Refraction depends on viewing angles. Look at an object from top (side), the surface looks shinnier with more refraction (less shiny and more reflection).
\\
\deff{Fresnel's Equation} determines the \textbf{ratio} of reflected and transmitted light energy from a perfect surface:
\[
F = \frac{1}{2} \Big(  
\frac{\sin^2(\phi - \theta)}{\sin^2(\phi + \theta)} + 
\frac{\tan^2(\phi - \theta)}{\tan^2(\phi + \theta)}
\Big)
\]
, where $\phi$ and $\theta$ are angles of incidence and refraction, and $\mu = \sin\phi / \sin\theta$ is the refractive index of the material.
\\
\deff{Schlick's Approximation} approximates Fresnel's Equation:
\[
F = f + (1 - f) (1 - V \cdot N)^5,  \; \text{for }  f = \frac{(1 - n_1 / n_2)^2}{1 + n_1 / n_2)^2}
\]

\subsubsection{Chromatic Aberration}
\deff{Chromatic Aberration} - Realistic (flawed) cameras produce images where different colour rays do not converge on the same point. Instead, there are slightly different extents of refraction for different colour components.
\\
\underline{Solution}: Use different refractive indices for RGB channels.





\section{6. FBO \& Real-Time Shadow}
\deff{Multi-Pass Rendering} - render 3D scenes for multiple times (passes), and combine the multiple rendered images to synthesize the final frame.

\subsection{Framebuffer Object}
\deff{Framebuffer Object} (FBO) - Framebuffers created in OpenGL for storing rendering outputs, that can be non-displayable.
\\
Each FBO contains many \deff{Attachment Points}, i.e. rendering destinations, with two types of FBO attachable images:
\begin{enumerate}
	\item Texture images, render to texture
	\item Render buffer images, offsceen rendering
\end{enumerate}
\underline{Note}: \deff{Mutliple Render Targets} (MRT) enables a fragment shader writes to (the same position of) multiple FBOs in one pass at the same time.


\subsection{Real-Time Shadow}
Point light sources produce shadows with \textbf{hard boundaries}, while extended light sources give \textbf{soft bounaries}, with \deff{Umbra} and \deff{Penumbra}.
\\
\underline{Note}: Real-time shadow rendering techniques assume \textbf{point light sources} and generate \deff{Geometric Shadows} (shadows with correct shapes and arbitrary intensities).

\subsubsection{Shadow Volume Method}
\underline{Idea}: An occluder casts a shadow volume. After determining the occlusion boundaries for each occluder, use stencil buffer to keep trace of how many are occluding the current pixel.
\\
\deff{Stencil Buffer} has the same resolution as colour buffer, and each stencil “pixel” is an integer counter.

\smallskip

Procedure for \deff{Depth Pass Method}:
\begin{enumerate}
	\item Find silhouette edges
	\item Extend silhouette edges from light source to form shadow volume polygons
	\item Render the scene as if it were completely in shadow
	\item Disable writes to the depth and color buffers
	\item Draw all \textbf{front faces} of shadow volume, and increment stencil buffer by 1 on \textbf{depth pass}
	\item Draw all \textbf{back faces} of shadow volume, and decrement stencil buffer by 1 on \textbf{depth pass}
	\item Render the scene again as if it were completely lit, using the stencil buffer to mask the shadowed areas
\end{enumerate}
\underline{Analysis}: [1] It draws only on pixels whose stencil value is 0. [2] \textbf{Fail} if the viewpoint is in a shadow volume or some shadow volume polygons are clipped by the near plane.

\smallskip

Procedure for \deff{Depth Fail / Carmack's Reverse Method}:
\\
Same steps as Depth Pass Method except for how it draws (i.e. Step 5 and 6)
\begin{itemize}
	\item Draw all \textbf{back faces} of shadow volume, and increment stencil buffer by 1 on \textbf{depth fail}
	\item Draw all \textbf{front faces} of shadow volume, and decrement stencil buffer by 1 on \textbf{depth fail}
\end{itemize} 


\subsubsection{Shadow Mapping Method}
\underline{Idea}: Objects are in shadow when their depth map values when viewing from the light source are smaller.
\\
Procedures:
\begin{enumerate}
	\item Render the scene using the light source as viewpoint
	\item Save the depth buffer known as \deff{Shadow Map}
	\item Clear the framebuffer
	\item Render the scene from camera’s viewpoint: For each fragment, transform it to the "light space" and compare its "light space" $z$-value with shadow map $z$-value.
	If "light space" $z$-value is larger, the fragment is in shadow \& lit with only ambient light. Otherwise, the fragment is not in shadow \& is fully lit.
\end{enumerate}

For each point $\vec{p}_M$ in modelling coordinates, its shadow mapp coordinates $\vec{p}_L$ is
\[
\vec{p}_L = B \cdot P_L \cdot V_L \cdot M \cdot \vec{p}_M
\]
, where $M, V_L, P_L$ are the \textbf{Modelling Matrix}, \textbf{Light's View Transformation Matrix}, \textbf{Light's Projection Matrix}, and $B$ is defined as
\[
B = S(\frac{1}{2}, \frac{1}{2}, \frac{1}{2}) \ T(1, 1, 1) = \begin{bmatrix}
	0.5 	& 0 	& 0		& 0.5 \\
	0	 	 & 0.5 	& 0		& 0.5 \\
	0        & 0 	 & 0.5	& 0.5 \\
	0 		 & 0 	& 0		& 1
\end{bmatrix}
\]

\underline{Issue 1}: Shadow Acnes \& Self-Shadowing
\\
\underline{Solution}:  [1] Subtract a tolerance value from \codein{ShadowCoord.z}. [2] Offset the scene backwards when generating the shadow map using \codein{glPolygonOffset()}.

\smallskip

\underline{Issue 2}: Jaggies at shadow boundaries
\\
\underline{Solution}: Use \deff{Percentage Closer Filtering} to smoothen, which averages depth comparison results in a small neighbourhood in the shadow map.





\section{7. Post-Rendering Processing}
\deff{Post Rendering Image Processing} \textasciitilde Further processing of images produced by 3D rendering, in order to produce final frame.

\subsection{Edge Detection}
It uses 2D digital convolution with \deff{Sobel Operator}, which is defined as:
\[
S_x = \begin{bmatrix}
-1 & 0 & 1 \\
-2 & 0 & 2 \\
-1 & 0 & 1
\end{bmatrix} \ , \;
S_y = \begin{bmatrix}
-1 & -2 & -1 \\
0 & 0 & 0 \\
1 & 2 & 1
\end{bmatrix}
\]

Procedures for edge detection:
\begin{enumerate}
    \item Apply convolution to the image with Sober Operator kernels. Let results be $s_x$ and $s_y$. 
    \item Compute for each pixel $g = \sqrt{s^2_x + s^2_y}$.
    \item If a pixel has $g$ above a threshold, consider it an edge pixel. 
\end{enumerate}


\subsubsection{Window Coordinates \& Texel Coordinates}
\underline{Window Coordinates}: A fragment’s 2D position relative to the window. Consider \textbf{the center of} the fragment. For bottom-leftmost pixel, it is \codein{gl\_FragCoord.x == gl\_FragCoord.y == 0.5}.
\\
\underline{Texel Coordinates}: Indices of the texture map (as a 2D array). For bottom-leftmost toxel, it is $(0, 0)$. Used in \codein{texelFetch()}.
\\
\underline{Texture Coordinates}: Normalised coordinate values of the texture map $\in [0, 1]^2$. For the bottom-leftmost corner, it is $(0.0, 0.0)$. To calculate the coordinates of the center of a texel, average the coordinates of the corners. Used in \codein{texture()}.
\\
\underline{Note}: For all coordinate systems above, $x$ \& $y$-coordinate correspond to width from left to right, \& height from bottom to top.

\subsection{Gaussian Blurring}
2D \deff{Gaussian Kernel / Filter} is defined as:
\[
\begin{aligned}
G(x, y) &= \frac{1}{2\pi\sigma^2} e^{-\frac{x^2+y^2}{2\sigma^2}}
\\
&= G(x)G(y) \ , \; G(x) = \frac{1}{2\pi\sigma^2} e^{-x^2/2\sigma^2}
\end{aligned}
\]

It is \deff{separable} as we can express the operation as two 1D Gaussian operations.
\\
2D Digital Convolution for Gaussian Blurring is:

\[
\begin{aligned}
C_{lm} 
& \leftarrow \sum_{i=-4}^{4} \sum_{i=-4}^{4} \frac{G(i,j)}{k} C_{l+i, m+j}
\\
& \leftarrow \sum_{i=-4}^{4} \frac{G(i)}{k} \sum_{j=-4}^{4} \frac{G(i,j)}{k} C_{l+i, m+j}
\\
\text{for } k &= \sum_{i=-4}^4 G(i)
\end{aligned}
\]

\underline{Note}: All Gaussian weights must sum to $1$.

Since it can be done using two 1D convolution, we can perform it in 3 passes efficiently:
\begin{enumerate}
    \item Bind to 1st FBO \& render 3D scene normally to a texture.
    \item Bind to 2nd FBO \& apply \textbf{vertical} Gaussian blur to Pass 1 texture \& write to another texture.
    \item Bind to 3rd FBO \& apply \textbf{horizontal} Gaussian blur to Pass 2 texture \& write to output colour buffer.
\end{enumerate}





\section{8. Deferred Shading}
% \subsection{Overview}
\deff{Deferred Shading} - Techniques to avoid applying complex shaders on fragments not appeared in the final image, based on multi-pass rendering.
\begin{enumerate}
    \item 1st Pass uses a simple shader to render scene into off-screen buffers with depth info, stored in \deff{Geometry Buffer / G-Buffer} for shading computations.
    \item 2nd pass applies frag.shader on G-buffer data to compute for each output pixel.
\end{enumerate}
\underline{Note}: Writing to G-buffer can be (time \& memory) expensive, so deferred shading is used only when direct computation very expensive. Usually used when: 1) High depth complexity / many overdraw, 2) Almost fill entire viewport, \&/or 3) Expensive shading.


\subsection{Screen Space Techniques}
\deff{Ambient Occlusion} - Technique to simulate illumination on \textbf{diffuse} surfaces by a \deff{uniform hemispherical area light source}.
\\
\underline{Procedures}: [1] For each surface point, pre-computing \deff{Visibility / Accessibility} factor, proportion of hemisphere centered about the surface normal visible from the point. [2] Use the factor to modulate direct diffuse illumination during rendering.
\\
\underline{Issues}: [1] Accessibility factor at each vertex can be computed by shooting rays around, expensive! [2] Pre-computed factors cannot be used for dynamic scenes.

\smallskip

Solution for expensive AO: \deff{Screen-Space Ambient Occlusion} (SSAO) \textasciitilde Apply deferred shading and compute accessibility only for output fragments based on depth map info.

% TODO: need more?





\section{9. Ray Tracing}
In modern OpenGL, ray tracing is performed in \textbf{fragment shader}.

\subsection{Ray Tracing Acceleration}
\subsubsection{Bounding Volume Methods}
\deff{(Naive) Bounding Volume} \textasciitilde Use a simple shape to enclose each complex object. Quick reject if ray does not intersect the volume.
\\
\underline{Note}: Trade-off between intersection efficiency \& tightness for rejection rate.

\smallskip

\deff{Bounding Volume Hierarchy} \textasciitilde Improvement to Bounding Volume method by organising volumes into hierarchies.
\\
\underline{Note}: Good hierarchies usually constructed manually.


\subsubsection{Spatial Subdivision Methods}
\deff{Spatial Subdivision Method} - Subdivide 3D space into regions \& associate each region with a list of objects that occupy (fully or partially) the region. When a ray is traced into a region, query the object list and perform intersection tests with objects.
\\
Choices for subdivision shape: 1) Uniform Grid, 2) Octree, 3) Binary Space Partitioning (BSP).

\smallskip

\deff{Octree} \textasciitilde Each cube region is conditionally \& recursively subdivided into 8 equal subregions.
\\
Two subdivision schemes
\begin{enumerate}
    \item Subdivide a cell if occupied by more than 1 object
    \item Subdivide a cell if occupied, until maximum depth
\end{enumerate}



\subsection{Distribution Ray Tracing}
\deff{Distribution Ray Tracing} - For each pixel, shoot multiple random rays to perform ray tracing. At each intersection, \textbf{randomly perturb} reflection, refraction \& shadow rays according to some distribution.
\\
\underline{Analysis}: Two sources of randomness: 1) shoot random rays, 2) add random perturbations during interaction.




% -----
\section{10. Local Reflection}
\deff{Local Reflection} \textasciitilde Consider relationship between a light source, a surface point \& a view point.
\\
\deff{Global Illumination} \textasciitilde Consider all light sources \& surfaces.
\\
\underline{Note}: [1] Local reflection involves no interaction with other objects. [2] Shadow is global illumination.

\smallskip

Local reflection improves material appearances by improving reflection, \deff{Bi-directional Reflection Distribution Function} (BRDF), \& transmission, \deff{Bi-directional Transmission Distribution Function} (BTDF).


\subsection{Radiometry Basics}
\deff{Radiometry} - The study of physical measurement of light / radiation energy.
\begin{itemize}
    \item \deff{Radiant Power} / \deff{Radiant Flux}, $\Phi$ - Total energy flows from/to/through a surface per unit time. (Unit Watts, $W$)
    \item \deff{Irradiance}, $E$ - Incident (incoming) radiant power on a surface per unit surface area, $E = \frac{d\Phi}{dA}$. (Unit $W / m^2$)
    \item \deff{Radiant Exitance}, $M$ / \deff{Radiosity}, $B$ - Exitant (outgoing) radiant power from a surface per unit surface area, $M = B = \frac{d\Phi}{dA}$. (Unit $W/m^2$)
    \item \deff{Radiance}, $L$ - Radiant power per unit projected surface area per unit solid angle. (Unit $W / (sr \ m^2)$)
    \[
    L = \frac{d^2\Phi}{d\omega dA\cos\theta}
    \]
\end{itemize}
\underline{Notes}: [1] $L$ invariant along straight paths. [2] Sensors' response proportionate to $L$ incident upon them.


\subsubsection{Bi-directional Reflection Distribution Function}
\deff{Bi-directional Reflection Distribution Function} - Specify the amount of incident light reflected in an exitant direction.
\[
\begin{aligned}
\text{BRDF}, \ f_r(x, \Psi \to \Theta)
&= \frac{dL(x \to \Theta)}{dE(x \leftarrow \Psi)}
\\
&= \frac{dL(x\to \Theta)}{L(x \leftarrow \Psi)(N_x \cdot \Psi) d\omega_\Psi}
\end{aligned}
\]
, where $x$ is surface point, $\Psi = L, \Phi = V$ light source \& sensor.

\underline{Note}: Radiosity quantities vary with wavelength. \textbf{Therefore we need a separate BRDF for each of RGB components}.
\\

BRDF Properties
\begin{itemize}
    \item \deff{Helmholtz Reciprocity} - BRDF is symmetric wrt. the incident and reflected directions.
    \[
    f_r(x, \Psi \to \Theta) = f_r(x, \Theta \to \Psi)
    \]
    \item Energy Conservation - Total power reflected in all directions must be equal or less than incident power.
    \[
    \int_{\Omega_x} f_r(x, \Psi\to\Omega) (N_x \cdot\Theta)d\omega_\Theta \le 1, \ \forall \Psi
    \]
\end{itemize}

%TODO: Examples


\subsection{Cook-Torrance Reflection Model}
\deff{Cook-Torrance / Torrance-Sparrow Reflection Model} - A physically based \textbf{specular reflection} model that models surfaces using \deff{Microfacets} which are simplified as symmetric V-shaped grooves.
\[
f_r(x, \Psi \leftrightarrow \Theta) = \frac{D(\alpha) GF}{(N\cdot \Psi)(N\cdot \Theta)\pi} 
+ \frac{k_d}{\pi}
\]
\underline{Note}: Diffuse one can be calculated using other methods \& overall effect is $sR_s + dR_d$ subject to $s+d=1$.
\\
\underline{Analysis}: [1] Assume microfacets are perfectly clearn. [2] CTRM BRDF is isotropic, \& cannot model anisotropic behaviours for objects like brushed metals, clothes or fur.
\\
\deff{Isotropic} - BRDF is independent of the azimuth angle $\phi$ of incident light (look the same around $360^\circ$ left to right).
\[
f_r(x, (\theta_o, \phi_i) \leftrightarrow (\theta_o, \phi_o))
= f_r(x, (\theta_o, 0) \leftrightarrow (\theta_o, \phi_o - \phi_i))
\]
A BRDF that is not isotropic is \deff{Anisotropic}.

\smallskip

Four components
\begin{enumerate}
    \item Statistical distribution of microfacets' orientation $D(\alpha)$
    \item Shadowing \& Masking effects, $G$
    \item Glare effect, $(N \cdot V)$
    \item Fresnel term, $F$
\end{enumerate}

\subsubsection{CTRM - Microfacet Distribution}
Model proportion of microfacets facing a given direction, $D(a)$, typically using a simple \textbf{Normal Distribution}:
\[
D(\alpha) = k \exp(-(\alpha / m)^2)
\]
, where $\alpha$ is angle between $N$ and $H$, and $m$ controls mean surface roughness.

\subsubsection{CTRM - Shadowing \& Masking}
Some light might be trapped or intercepted, leading to \deff{Masking}, cannot go out along reflected, \&/or \deff{Shadowing}, incident light being blocked.
\[
\begin{aligned}
G &= \min \{1, G_s, G_m \}
\\
G_m &= 2(N\cdot H)(N\cdot V) / V \cdot H
\\
G_s &= 2(N\cdot H)(N \cdot L)/V\cdot H
\end{aligned}
\]

\subsubsection{CTRM - Glare Effect}
\deff{Glare Effect} - When angle between the view vector and the mean surface normal increases, an observer sees more microfacets.
\\
\underline{Implementation}: [1] Modelled with the term $1/{N \cdot V}$. [2] Countered by masking effect if viewing direction almost parallel to mean surface.



\section{11. Global Illumination}
\subsection{Rendering Equation}
\deff{Hemispherical Formulation}
\[
\begin{aligned}
L_\text{ref}(\mathbf{x}, \omega_\text{ref}) 
&= L_e(\mathbf{x}, \omega_\text{ref}) 
\\
&+ \int_s \rho(\mathbf{x}, \omega_\text{in} \to \omega_\text{ref})L_\text{in}(\mathbf{x}', \omega_\text{in}) \cos \theta_\text{in} d\omega_\text{in}
\end{aligned}
\]
\deff{Area Formulation}:
\[
\begin{aligned}
L_\text{ref}(\mathbf{x}, \omega_\text{ref}) 
&= L_e(\mathbf{x}, \omega_\text{ref}) 
\\
&+ \int_s \rho(\mathbf{x}, \omega_\text{in} \to \omega_\text{ref})L_\text{in}(\mathbf{x}', \omega_\text{in}) g(\mathbf{x}, \mathbf{x}') \cos \theta_\text{in} \, \frac{\cos \theta_0 dA}{\lVert \mathbf{x} - \mathbf{x}' \rVert}^2
\end{aligned}
\]
, where $g(\mathbf{x}, \mathbf{x}')$ is the \deff{Visibility Function}, \& $d\omega_\text{in} = \frac{\cos \theta_0 dA}{\lVert \mathbf{x} - \mathbf{x}' \rVert}^2$ projected area of the differential surface region visible in direction $\omega_\text{in}$.
\\
\underline{Analysis}: [1] View-independent. [2] Recursive \& complicated, cannot be evaluated analytically, so numeric methods like Monte Carlo are used.

\subsubsection{Monte Carlo Integration}
\deff{Monte Carlo Integration} - A method of evaluating an integral by generating random samples of the integrand \& taking the average.
\\
Sampling techniques determine accuracy / efficiency of Monte Carlo estimates:
\begin{itemize}
    \item \deff{Uniform Sampling}. Error $\propto 1 / \sqrt{N}$.
    \item \deff{Stratified Sampling} - Subdivide domain into non-overlapping regions, \& take one random sample per region. Error $\propto 1/ N$.
    \item \deff{Importance Sampling} - Sample the integrand with probability similar to the value of the integrand. Error depends on choice of probability function chosen.
\end{itemize}


\subsection{Ray Tracing Models}
\deff{Light Transport Model} \textasciitilde Consider reflection as (totally) specular or (totally) diffuse for surface-to-surface interaction. Use regex-liked notations to describe light transportation.

\begin{itemize}
    \item \codein{L} light source; \codein{E} eye; \codein{S} specular reflection; \codein{D} diffuse.
    \item For any event \codein{e}: \codein{(e)+} one or more; \codein{(e)*} zero or more; \codein{(e)?} zero or one; \codein{(e|f)} either one.
\end{itemize}


\subsubsection{Model: Whitted Ray Tracing}
\underline{Analysis}: [1] View-independent. [2] Simulate \codein{LD?S*E}. [3] A hybrid method: both global \& local model, and global parts only covers \textbf{pure specular-specular interaction}.


\subsubsection{Model: Distribution Ray Tracing}
\underline{Analysis}: [1] View-dependent. [2] Simulate \codein{LD?S*E}, but all specular paths are calculated, not just in mirror reflection direction.


\subsubsection{Model: Path Tracing}
\underline{Procedures}: 1) For each pixel, shoot multiple random primary rays. 2) At each intersection, shoot any one secondary ray. 3) Terminate either when the ray hits nothing or based on \deff{Russian Roulette Technique} for absorption, where randomly at an intersection, absorb / despawn with a probability proportional to material absorption.
\\
\underline{Note}: Linear complexity, as one secondary ray every time.
\\
\underline{Analysis}: [1] View-dependent. [2] Simulate \codein{L(D|S)*E}. [3] Complete global illumination. [4] Linear complexity but high computational cost, need many rays for indirect illumination effects like caustics.


\subsubsection{Model: Two-Pass Ray Tracing}
\underline{Procedures}
\begin{itemize}
    \item First Pass, \deff{Light Pass}: Rays are shot from the light sources \& followed through transparent \& specular objects until they hit a diffuse surface. Cache light energy on diffuse surfaces.
    \item Second Pass, \deff{Eye Pass}:  Use conventional ray tracing. Terminate on the diffuse surface \& uses the stored energy in the illumination map.
\end{itemize}

\underline{Analysis}: [1] First pass view independent, second view-dependent. [2] Simulate \codein{LS+DS*E}. [3] More efficient than path tracing.


\subsubsection{Model: Photon Mapping}
\deff{Photon Mapping} \textasciitilde Emit photons towards all surfaces, \& store when hitting a diffuse surface. Randomly determine to reflect, transmit or absorb. For each photon, store [1] incoming direction, \& [2] light power, using \textbf{KD-Tree} based on 3D location.
\\
\underline{Procedsures} based on Two-Pass Rendering
\begin{itemize}
    \item First pass, \textbf{Photon Tracing}: Build photon map structure by tracing photons from lights through the model.
    \item Second Pass, \textbf{Rendering}: Render model from eye using photon map information.
\end{itemize}


\subsubsection{Model: Radiosity + Path Tracing}
\deff{Radiosity} \textasciitilde Discretise scene into patches, consider interaction between patches. Solution expressed in terms of a constant radiosity for each patch.
\\
\underline{Analysis}: [1] View-independent. [2] Simulate \codein{LD*E}.

\smallskip

\textbf{Radiosity with Path Tracing}: Trace rays from light sources \& cache the irradiance on diffuse surfaces. Radiosity solution uses the cached irradiance as patch emission.
\\
\underline{Analysis}: Simulate \codein{LS*D*S*E}.






\section{12. Radiosity}
\deff{Radiosity} \textasciitilde An approximation algorithm for modelling diffuse-to-diffuse interaction in the scene by discretising the scene into patches \& calculating diffuse-to-diffuse interaction between patches. Based on Rendering Equation:
\[
\begin{aligned}
B_i 
&= E_i + R_i \int_j B_j F_{ij}
\\
&\approx E_i + R_i \sum_{j=1}^n B_j F_{ij}
\end{aligned}
\]
\underline{Intuitively}, it is $\text{radiosity} \times \text{area} = \text{emited power} + \text{reflected power}$.
\\
\underline{Note}: Iterative / numerical methods are used to solve the system of linear systems for $B_i$. [2] $E_i, R_i$ are \textbf{wavelength-dependent}, a separate set of equations for each of RGB.


\subsection{Solving Linear Equations}
\subsubsection{Algorithm: Gaussian Elimination}
\underline{Analysis}: [1] Able to get exact solution but unnecessary for radiosity. [2] Time complexity $O(n^3)$.

\subsubsection{Algorithm: Jacobi Iteration / Gauss-Seidel Method}
\deff{Jacobi Iteration} - For a system of linear equations $A\mathbf{x} = E$, 
\begin{enumerate}
    \item Initial approximation $x_i^{(0)} = E_i / a_{ii}$
    \item Compute $x_i^{(k+1)}$ iteratively using:
    \[
    x_i^{(k+1)} = (E_i - \sum_{j=1}^n a_{ij}x_j^{(k)}) / a_{ii}, \ \forall i
    \]
    \item Stop iteration if $|x_i^{(k+1)} - x_i^{(k)}| < \epsilon$ for pre-set threshold $\epsilon > 0$.
\end{enumerate}
\deff{Gauss-Seidel Method} - It improves Jacobi Iteration by using previous unknowns' estimates from the current iteration for all subsequent unknowns:
\[
x_i^{(k+1)} = (E_i - \sum_{j=1}^{i-1} a_{ij}x_j^{(k+1)}- \sum_{j=i}^{n} a_{ij}x_j^{(k)}) / a_{ii}, \ \forall i
\]


\subsection{Form Factors}
\deff{Form Factor}, $F_{ij}$ - proportion of energy leaving surface $i$ \& striking surface $j$ directly over total energy that leaving surface $i$.
\\
Form factor for patches can be approximated by sum over $A_i$.
\[
\begin{aligned}
F_{ij} &= \frac{1}{A_i} \int_{A_i} \int_{A_j} \frac{\cos \phi_i \cos \phi_j}{\pi r^2} dA_j dA_i
\\
F_{dA_iA_j} &\approx \int_{A_j} \frac{\cos \phi_i \cos \phi_j}{\pi r^2} dA_j
\end{aligned}
\]
\underline{Note}: $\int F_{ij} dA_j = 1$.

\subsubsection{Nusselt Analogue \& Hemicube}
\deff{Nusselt Analogue} - The form factor between $dA_i$ and $A_j$ can be obtained by projecting $A_j$ onto the surface of a \textbf{unit hemisphere} then projecting onto a \deff{unit circle} on plane of $dA_i$, both centered at $dA_i$.

\smallskip

\deff{Hemicube} \textasciitilde Replace the unit hemisphere with half of a cube, i.e. $C = [-1, 1]\times[-1, 1]\times [0, 1]$.
\\
\underline{Analysis}: Instead of double projection onto the plane, now there is one projection, onto the top or side faces of the hemicube.
\\
\deff{Delta Form Factor} - Amount of form factor contributed by a pixel on hemicube surface, if it is projected,
\begin{itemize}
    \item Top $(x, y, 1)$: $\triangle F_q = \frac{1}{\pi(x^2+y^2+1)^2} \triangle A$
    \item Side $(1, y, z)$: $\triangle F_q = \frac{x}{\pi(1+y^2+z^2)^2} \triangle A$, same for other 3
\end{itemize}
\underline{Implementation}: 1) Consider a hemicube centred at patch $i$ 2) Render and project all other patches onto the hemicube using hidden surface removal. 3) Find the pixels covered by each patch, and sum up their delta form factors.
\\
\underline{Note}: Based on \deff{Item Buffering}, namely using colour buffer where each colour servers as a unique identifier.


\subsection{Adaptive Subdivision}
\subsubsection{Subdivision Methods}
\deff{(Naive) Adaptive Subdivision}: 1) Use initial patches to compute a radiosity solution. 2) For every patch, subdivide if its local radiosity variation is large. 3) Recompute radiosity solution (from scratch) using all patches and sub-patches. 4) Repeat Step 2 \& 3 until all local radiosity variations are within a threshold.
\\
\underline{Analysis}: Excessive re-computation: complexity $O((n+k)^2)$ for initial number of patches $n$ new sub-patches $k$.

\smallskip

\deff{Sub-structuring Adaptive Subdivision} \textasciitilde (Improvement) During each subdivision of patch $i$, only compute form factors from each new sub-patch $i1, ..., ik$ to initial patches:
\[
B_{iq} = E_i + R_i \sum_{j=1}^n B_j F_{(iq)j}, \, q = 1, 2, ..., k
\]
\underline{Analysis}: [1] Complexity $O(nk)$. [2] Simple heuristic for hemicube: Subdivide if patch area is large compared to distance to nearest patches.


\subsubsection{Progressive Refinement}
\deff{Progressive Refinement} \textasciitilde A stream-based approach that continuously subdivides large (in terms of radiosity) patches until all small enough, addressing the issue of huge number of patches need to be first calculated requiring excess memory.
\\
\underline{Procedure}: 1) Find patch $i$ with greatest unshot radiosity / emitted energy. 2) Compute form factors from patch $i$ to all others. 3) Update the radiosity of each of the receiving patches.
4) If the new greatest unshot radiosity is below a threshold, stop the algorithm, otherwise repeat from Step 1.
\\
Progressive Refinement updates patches using \deff{Shooting} \textasciitilde A single step commutes form factors from shooting patch to all receiving patches \& distribute unshot energy $\triangle B_i$:
\[
B_j^{(k+1)} = B_j^{(k)} + R_j F_{ji} \triangle B_i
\]
\underline{Note}: Update in $B_j$ leads to unshot energy in $B_j$, for update in next iteration.





\noindent\rule{8cm}{0.4pt}

\section{Others}
\subsection{Multi-Variable Calculus Misc}
For a 3D surface $z = f(x, y), (x, y) \in D$ and $D \subseteq \mathbb{R}^2$, normal vector at surface point $(x, y, z)$ is parallel to:
\[
(\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \pm 1)
\]

\smallskip

Projected area of a plane with area $s$ \& normal $N$ onto unit dir. $\Psi$:
\[
s_\text{proj} = \cos \langle N, \Psi \rangle s = (N \cdot \Psi) s 
\]


% \subsection{From Tutorials \& Assignments}


\subsection{From Past Year Papers}
\citeqn{(AY19/20 Sem2 Midterm Qn2B)} Vectors like \codein{ecNormal} need to be normalised again in fragment shader even though the corresponding ones in vertex shader is normalsied, because normal vectors at vertices are bilinearly interpolated to the fragment, \& resultings vector may not be a unit vector anymore.
\\
\citeqn{(AY19/20 Sem2 Midterm Qn5B)} Encoded perturbed normal vectors stored in a RGB image appears light blue, because unperturbed normal is $(0, 0, 1) \in [-1, 1]^3$ and encoded to $(0.5, 0.5, 1) \in [0, 1]^3$.
\\
\citeqn{(AY19/20 Sem2 Midterm Qn6B)} Mipmapping is not effective for shadow mapping boundary jaggies, as mipmapping only averages depth values while comparison results are still binary.
\\
\citeqn{(AY19/20 Sem2 Final Qn29)} If all patches in an enclosed space reflect all incoming light, the equilibrium radiosity will be \textbf{infinity} for all patches (\& the linear system inconsistent).
\\
\citeqn{(AY20/21 Sem2 Midterm QnD3)} Differences between \codein{texture()} and \codein{texelFetch()}:
\begin{itemize}
    \item Data - Former takes a normalised value in $[0, 1]^2$ while latter uses exact int-valued texel coordinates.
    \item Retrieval - Former performs texture filtering based on the sampling parameters specified, while latter retrieves the exact one texel.
\end{itemize}


% \citeqn{(AY20/21 Sem2 Midterm QnG)} When to use Shadow Volume vs. Shadow Mapping Algorithms:
% \\
% \citeqn{(AY21/22 Sem2 Midterm Qn14)} Advantage of Shadow Volume methods over Shadow Mapping: 













% -----
\noindent\rule{8cm}{0.4pt}
\section{GLSL Coding}
\subsection{Math}
\codein{genType sqrt(genType x)} - To compute the square root of input.
\\
\codein{genType min(genType x, genType y)} - To compute the min of two inputs. Similarly for \codein{min(x,y)}.
\\
\codein{genType pow(genType x, genType y)} - To compute the power $x^y$.
\\
\codein{genType dFdx(genType p)} - To compute the partial derivative of input wrt. $x$. Similarly for \codein{dFdy()}.
\codein{float dot(genType x, genType y)} - To compute the dot produce. Similarly for \codein{cross()}.
\\
\codein{float length(genType x)} - To compute the L2 length of the vector.
\\
\codein{genType normalize(genType v)} - To normalize the input vector.
\\
\codein{genType reflect(genType I, genType N)} - To calculate reflected direction vector.



\subsection{Fragment Shader}
\codein{gvec4 texture(sampler, P)} - To sample texture from the sampler using texture coordinates.
\\
\codein{gvec4 textureProj(sampler, P)} - To first compute the query vector of $P$ using perspective division, then sample texture.
\\
\codein{gvec4 textureProjOffset(sample, P, offset)} - To compute a texture lookup with projection and offset.
\\
\codein{gvec4 texelFetch(sampler, P, lod)} - To sample texture from sampler using texel coordinates. Usually \codein{lod = 0} for Level of Details.
\\
\underline{Note}: Return types, \codein{P} \& \codein{offset} can all be vectors of size $1~4$ depending on params.

% -----
% KIV:
% 

% -----
% Others:
% 5. check whats n_1, n_2 in Schlick's Approx.


% -----
% Include img:
% opengl pipeline


\end{multicols}
\end{document}
